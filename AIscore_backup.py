import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import os
import numpy as np
import csv

target_dataset = []
score_dataset = []
path = "/home/kali/Desktop/ExploitExpert/data"

# for ip in range(255):
#     if os.path.exists(os.path.join(path, 'target_info_192.168.159.' + str(ip) + '.json')) is True:
#         target_dataset.append('target_info_192.168.159.' + str(ip) + '.json')

# target = []
# for target_json in target_dataset:
#     target_csv = pd.read_json(os.path.join(path, target_json))

# print(target_csv)
# df=pd.DataFrame({'target_ip':target_csv['rhost'],
#                  'os_type':target_csv['os_type']
#                  })

# print(df)

# for ip in range(255):
#     if os.path.exists(os.path.join(path, 'target_info_192.168.159.' + str(ip) + '.csv')) is True:
#         target_dataset.append('target_info_192.168.159.' + str(ip) + '.csv')
# target = []
# for target_csv in target_dataset:
#     with open(os.path.join(path, target_csv), "r", newline="") as f:
#         reader = csv.reader(f)
#         # headers = next(reader)
#         for h in reader:
#             if h not in target:
#                 target.append(h)

# with open(os.path.join(path, "target_dataset.csv"), "w", newline="") as merge:
#     writer = csv.DictWriter(merge, fieldnames=target)
#     for target in target_dataset:
#         with open(os.path.join(path, target), "r", newline="") as f:
#             reader = csv.DictReader(f)
#             for line in reader:
#                 writer.writerow(line)

for ip in range(255):
    if os.path.exists(os.path.join(path, 'target_info_192.168.159.' + str(ip) + '.csv')) is True:
        target_file = os.path.join(path, 'target_info_192.168.159.' + str(ip) + '.csv')
        data = pd.read_csv(target_file)
        one_hot = np.array(pd.get_dummies(data))
        score = np.sum(one_hot)
        print(f'target_info_192.168.159.{str(ip)} exploit risk: {score}')
        score_dataset.append(score)
        if np.shape(one_hot)!=(5,126):
            rows, cols = np.shape(one_hot)
            i=cols
            while i<126:
                one_hot = np.column_stack([one_hot, [0,0,0,0,0]])
                i+=1
            target_dataset.append(one_hot)
        else:
            print(np.shape(one_hot))
            target_dataset.append(one_hot)

tf.random.set_seed(42)

expolit_model = tf.keras.Sequential([
    tf.keras.layers.Dense(1),
    tf.keras.layers.Dense(1)
])

expolit_model.compile(loss=tf.keras.losses.mae,
    optimizer=tf.keras.optimizers.SGD(),
    metrics=['mae'])

# target_file = os.path.join(path, "target_dataset.csv")
# data = pd.read_csv(target_file)
# one_hot = np.array(pd.get_dummies(data))
# x = np.array(one_hot)
# x = tf.constant(0, shape=(11,5,126))
# x = np.tile(target_dataset, (5))
# x = np.arange(one_hot).reshape((11))
# x = np.full((11,5,126), 0)
x = np.array(target_dataset)
y = np.array(score_dataset)
expolit_model.fit(x, y, epochs=100)