import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import os
import numpy as np
import csv
import sklearn
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

# sess = tf.compat.v1.Session()

path = "/home/kali/Desktop/ExploitExpert/data"
target_file = os.path.join(path, 'target_dataset.csv')
os_file = os.path.join(path, 'ostype.csv')
ser_file = os.path.join(path, 'services.csv')

if os.path.exists(target_file) is True:
    print('Get target dataset')
    data = pd.read_csv(target_file)
    dataset = data.drop('exploit_sucess', axis=1)
    y = data['exploit_sucess']

    ohe = OneHotEncoder()
    ohe.fit_transform(dataset)
    x = ohe.transform(dataset).toarray()

    # le = preprocessing.StandardScaler().fit(result)
    # print(le.transform(result))
    # cols = data.columns
    # columns = []
    # for features in cols:
    #     feature = tf.feature_column.categorical_column_with_identity(features, num_buckets=3, default_value=0)
    #     feature = tf.feature_column.indicator_column(feature)
    #     columns.append(feature)
    
    # inputs = tf.compat.v1.feature_column.input_layer(cols, columns)

    # init = tf.compat.v1.global_variables_initializer()
    # sess.run(tf.compat.v1.tables_initializer())
    # sess.run(init)
    # v = sess.run(inputs)
    # print(v)

    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)

    from sklearn.neighbors import KNeighborsClassifier

    clf = KNeighborsClassifier(n_neighbors=3)

    clf.fit(x_train, y_train)

    y_pred = clf.predict(x_test)

    print((1-clf.score(x_test, y_test))*100, "%"," exploitable")

    scores = []
    for n in range(1,8):
        clf = KNeighborsClassifier(n_neighbors=n)
        clf.fit(x_train, y_train)
        scores.append(clf.score(x_test, y_test))

    import matplotlib.pyplot as plt
    #%%matplotlib inline

    plt.plot(range(1,8),scores)
    plt.show()

    # tf.random.set_seed(42)

    # model = tf.keras.Sequential([
    #                                tf.keras.layers.Dense(50, activation='relu'),
    #                                tf.keras.layers.Dense(100, activation='relu'),
    #                                tf.keras.layers.Dense(200, activation='relu'),
    #                                tf.keras.layers.Dense(400, activation='relu')
    #                            ])
        
    # model.compile(loss=tf.keras.losses.mae,
    #               optimizer=tf.keras.optimizers.SGD(),
    #               metrics=['mae'])


    # model.fit(x_train, y_train, epochs=100)

    # y_pred = model.predict(x_test)
    # print(y_pred)
else:
    print('No dataset')
    exit(1)